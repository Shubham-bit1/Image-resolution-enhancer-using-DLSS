{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd01baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253",
   "display_name": "Python 3.8.8 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.layers import Input, Dense, Reshape, Flatten\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import skimage.transform as st"
   ]
  },
  {
   "source": [
    "# Set Parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Folder containing input (low resolution) dataset\n",
    "input_path = r'Data/LR'\n",
    "\n",
    "# Folder containing output (high resolution) dataset\n",
    "output_path = r'Data/HR'\n",
    "\n",
    "# Dimensions of the images inside the dataset.\n",
    "# NOTE: The image sizes must be compatible meaning output_dimensions / input_dimensions is a multiple of 2\n",
    "input_dimensions = (128,128,3)\n",
    "\n",
    "# Dimensions of the images inside the dataset.\n",
    "# NOTE: The image sizes must be compatible meaning output_dimensions / input_dimensions is a multiple of 2\n",
    "output_dimensions = (256,256,3)\n",
    "\n",
    "# How many times to increase the resolution by 2 (by appling the UpSampling2D layer)\n",
    "super_sampling_ratio = int(output_dimensions[0] / input_dimensions[0] / 2)\n",
    "\n",
    "# Folder where you want to save to model as well as generated samples\n",
    "model_path = \"DLSS_results\"\n",
    "\n",
    "# How many epochs between saving your model\n",
    "interval = 5\n",
    "\n",
    "# How many epochs to train the model\n",
    "epoch = 25\n",
    "\n",
    "# How many images to train at one time. Ideally this number would be a factor of the size of your dataset\n",
    "batch = 25\n",
    "\n",
    "# How many convolutional filters for each convolutional layer of the generator and the discrminator\n",
    "conv_filters = 64\n",
    "\n",
    "# Size of kernel used in the convolutional layers\n",
    "kernel = (5,5)\n",
    "\n",
    "# Boolean flag, set to True if the data has pngs to remove alpha layer from images\n",
    "png = True"
   ]
  },
  {
   "source": [
    "# Create Deep Convolutional GAN Class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN():\n",
    "    \n",
    "    # Initialize parameters, generator, and discriminator models\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Set dimensions of the output image\n",
    "        self.img_rows = output_dimensions[0]\n",
    "        self.img_cols = output_dimensions[1]\n",
    "        self.channels = output_dimensions[2]\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        \n",
    "        # Shape of low resolution input image\n",
    "        self.latent_dim = input_dimensions\n",
    "        \n",
    "        # Chose optimizer for the models\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "        generator = self.generator\n",
    "\n",
    "        # The generator takes low resolution images as input and generates high resolution images\n",
    "        z = Input(shape = self.latent_dim)\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    # load data from specified file path \n",
    "    def load_data(self):\n",
    "        \n",
    "        # Initializing arrays for data and image file paths\n",
    "        data = []\n",
    "        small = []\n",
    "        paths = []\n",
    "        \n",
    "        # Get the file paths of all image files in this folder\n",
    "        for r, d, f in os.walk(output_path):\n",
    "            for file in f:\n",
    "                if '.jpg' in file or 'png' in file:\n",
    "                    paths.append(os.path.join(r, file))\n",
    "                    \n",
    "        # For each file add high resolution image to array\n",
    "        for path in paths:\n",
    "            img = Image.open(path)\n",
    "            \n",
    "            # Resize Image\n",
    "            y = np.array(img.resize((self.img_rows,self.img_cols)))\n",
    "            \n",
    "            # Remove alpha layer if imgaes are PNG\n",
    "            if(png):\n",
    "                y = y[...,:3]\n",
    "                \n",
    "            data.append(y)\n",
    "          \n",
    "        paths = []\n",
    "        \n",
    "        # Get the file paths of all image files in this folder\n",
    "        for r, d, f in os.walk(input_path):\n",
    "            for file in f:\n",
    "                if '.jpg' in file or 'png' in file:\n",
    "                    paths.append(os.path.join(r, file))\n",
    "                    \n",
    "        # For each file add low resolution image to array\n",
    "        for path in paths:\n",
    "            img = Image.open(path)\n",
    "            \n",
    "            # Resize Image\n",
    "            x = np.array(img.resize((self.latent_dim[0],self.latent_dim[1])))\n",
    "            \n",
    "            # Remove alpha layer if imgaes are PNG\n",
    "            if(png):\n",
    "                x = x[...,:3]\n",
    "                \n",
    "            small.append(x)\n",
    "        \n",
    "            \n",
    "        # Return x_train and y_train reshaped to 4 dimensions\n",
    "        y_train = np.array(data)\n",
    "        y_train = y_train.reshape(len(data),self.img_rows,self.img_cols,self.channels)\n",
    "        x_train = np.array(small)\n",
    "        x_train = x_train.reshape(len(small),self.latent_dim[0],self.latent_dim[0],self.latent_dim[2])\n",
    "        \n",
    "        del data\n",
    "        del small\n",
    "        del paths\n",
    "        \n",
    "        # Shuffle indexes of data\n",
    "        X_shuffle, Y_shuffle = shuffle(x_train, y_train)\n",
    "        \n",
    "        return X_shuffle, Y_shuffle\n",
    "    \n",
    "    # Define Generator model\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "        \n",
    "        # 1st Convolutional Layer / Input Layer\n",
    "        model.add(Conv2D(conv_filters, kernel_size=kernel, padding=\"same\", input_shape=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        \n",
    "        # Upsample the data as many times as needed to reach output resolution\n",
    "        for i in range(super_sampling_ratio):\n",
    "        \n",
    "            # Super Sampling Convolutional Layer\n",
    "            model.add(Conv2D(conv_filters, kernel_size=kernel, padding=\"same\"))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            # Upsample the data (Double the resolution)\n",
    "            model.add(UpSampling2D())\n",
    "\n",
    "        # Convolutional Layer\n",
    "        model.add(Conv2D(conv_filters, kernel_size=kernel, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "        # Convolutional Layer\n",
    "        model.add(Conv2D(conv_filters, kernel_size=kernel, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        \n",
    "        # Final Convolutional Layer (Output Layer)\n",
    "        model.add(Conv2D(3, kernel_size=kernel, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=self.latent_dim)\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    # Define Discriminator model\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        # Input Layer\n",
    "        model.add(Conv2D(conv_filters, kernel_size=kernel, input_shape=self.img_shape,activation = \"relu\", padding=\"same\"))\n",
    "        \n",
    "        # Downsample the image as many times as needed\n",
    "        for i in range(super_sampling_ratio):\n",
    "            \n",
    "            # Convolutional Layer\n",
    "            model.add(Conv2D(conv_filters, kernel_size=kernel))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "        \n",
    "            # Downsample the data (Half the resolution)\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        \n",
    "        # Convolutional Layer\n",
    "        model.add(Conv2D(conv_filters, kernel_size=kernel, strides = 2))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "        # Convolutional Layer\n",
    "        model.add(Conv2D(conv_filters, kernel_size=kernel, strides = 2))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        \n",
    "        # Output Layer\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "    \n",
    "    # Train the Generative Adversarial Network\n",
    "    def train(self, epochs, batch_size, save_interval):\n",
    "        \n",
    "        # Prevent script from crashing from bad user input\n",
    "        if(epochs <= 0):\n",
    "            epochs = 1\n",
    "        \n",
    "        if(batch_size <= 0):\n",
    "            batch_size = 1\n",
    "\n",
    "        # Load the dataset\n",
    "        X_train, Y_train = self.load_data()\n",
    "        \n",
    "        # Normalizing data to be between 0 and 1\n",
    "        X_train = X_train / 255\n",
    "        Y_train = Y_train / 255\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        \n",
    "        # Placeholder arrays for Loss function values\n",
    "        g_loss_epochs = np.zeros((epochs, 1))\n",
    "        d_loss_epochs = np.zeros((epochs, 1))\n",
    "        \n",
    "        # Training the GAN\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            \n",
    "            # Initialize indexes for training data\n",
    "            start = 0\n",
    "            end = start + batch_size\n",
    "            \n",
    "            # Array to sum up all loss function values\n",
    "            discriminator_loss_real = []\n",
    "            discriminator_loss_fake = []\n",
    "            generator_loss = []\n",
    "            \n",
    "            # Iterate through dataset training one batch at a time\n",
    "            for i in range(int(len(X_train)/batch_size)):\n",
    "                \n",
    "                # Get batch of images\n",
    "                imgs_output = Y_train[start:end]\n",
    "                imgs_input = X_train[start:end]\n",
    "\n",
    "                # Train Discriminator\n",
    "\n",
    "                # Make predictions on current batch using generator\n",
    "                gen_imgs = self.generator.predict(imgs_input)\n",
    "\n",
    "                # Train the discriminator (real classified as ones and generated as zero)\n",
    "                d_loss_real = self.discriminator.train_on_batch(imgs_output, valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                #  Train Generator\n",
    "\n",
    "                # Train the generator (wants discriminator to mistake images as real)\n",
    "                g_loss = self.combined.train_on_batch(imgs_input, valid)\n",
    "                \n",
    "                # Add loss for current batch to sum over entire epoch\n",
    "                discriminator_loss_real.append(d_loss[0])\n",
    "                discriminator_loss_fake.append(d_loss[1])\n",
    "                generator_loss.append(g_loss)\n",
    "                \n",
    "                # Increment image indexes\n",
    "                start = start + batch_size\n",
    "                end = end + batch_size\n",
    "             \n",
    "            \n",
    "            # Get average loss over the entire epoch\n",
    "            loss_data = [np.average(discriminator_loss_real),np.average(discriminator_loss_fake),np.average(generator_loss)]\n",
    "            \n",
    "            #save loss history\n",
    "            g_loss_epochs[epoch - 1] = loss_data[2]\n",
    "            \n",
    "            # Average loss of real data classification and fake data accuracy\n",
    "            d_loss_epochs[epoch - 1] = (loss_data[0] + (1 - loss_data[1])) / 2\n",
    "                \n",
    "            # Print average loss over current epoch\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, loss_data[0], loss_data[1]*100, loss_data[2]))\n",
    "\n",
    "            # If epoch is at interval, save model and generate image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                \n",
    "                # Select 8 random indexes\n",
    "                idx = np.random.randint(0, X_train.shape[0], 8)\n",
    "                \n",
    "                # Get batch of training images\n",
    "                x_points = X_train[idx]\n",
    "                \n",
    "                # Make predictions on batch of training images\n",
    "                predicted_imgs = self.generator.predict(x_points)\n",
    "                \n",
    "                # Undo normalization of data. Update values to be between 0 and 255 for RGB image\n",
    "                predicted_imgs = np.array(predicted_imgs) * 255\n",
    "                np.clip(predicted_imgs, 0, 255, out=predicted_imgs)\n",
    "                predicted_imgs = predicted_imgs.astype('uint8')\n",
    "                x_points = np.array(x_points) * 255\n",
    "                np.clip(x_points, 0, 255, out=x_points)\n",
    "                x_points = x_points.astype('uint8')\n",
    "                \n",
    "                interpolated_imgs = []\n",
    "                \n",
    "                # Interpolate low resolution images for comparison\n",
    "                for x in range(len(x_points)):\n",
    "                    img = Image.fromarray(x_points[x])\n",
    "                    interpolated_imgs.append(np.array(img.resize((self.img_rows,self.img_cols))))\n",
    "                \n",
    "                # Plot the predictions next to the interpolated images\n",
    "                self.save_imgs(epoch, predicted_imgs, interpolated_imgs)\n",
    "                \n",
    "        return g_loss_epochs, d_loss_epochs\n",
    "    \n",
    "    # Save the model and generate prediction samples for a given epoch\n",
    "    def save_imgs(self, epoch, gen_imgs, interpolated):\n",
    "        \n",
    "        # Define number of columns and rows\n",
    "        r, c = 4, 4\n",
    "        \n",
    "        # Placeholder array for MatPlotLib Figure Subplots\n",
    "        subplots = []\n",
    "        \n",
    "        # Create figure with title\n",
    "        fig = plt.figure(figsize= (40, 40))\n",
    "        fig.suptitle(\"Epoch: \" + str(epoch), fontsize=65)\n",
    "        \n",
    "        # Initialize counters needed to track indexes across multiple arrays\n",
    "        img_count = 0;\n",
    "        index_count = 0;\n",
    "        x_count = 0;\n",
    "        \n",
    "        # Loop through columns and rows of the figure\n",
    "        for i in range(1, c+1):\n",
    "            for j in range(1, r+1):\n",
    "                # If row is even, plot the predictions\n",
    "                if(j % 2 == 0):\n",
    "                    img = gen_imgs[index_count]\n",
    "                    index_count = index_count + 1\n",
    "                # If row is odd, plot the interpolated images\n",
    "                else:\n",
    "                    img = interpolated[x_count]\n",
    "                    x_count = x_count + 1\n",
    "                # Add image to figure, add subplot to array\n",
    "                subplots.append(fig.add_subplot(r, c, img_count + 1))\n",
    "                plt.imshow(img)\n",
    "                img_count = img_count + 1\n",
    "        \n",
    "        # Add title to columns of figure\n",
    "        subplots[0].set_title(\"Interpolated\", fontsize=45)\n",
    "        subplots[1].set_title(\"Predicted\", fontsize=45)\n",
    "        subplots[2].set_title(\"Interpolated\", fontsize=45)\n",
    "        subplots[3].set_title(\"Predicted\", fontsize=45)\n",
    "                \n",
    "        # Save figure to .png image in specified folder\n",
    "        fig.savefig(model_path + \"\\\\epoch_%d.png\" % epoch)\n",
    "        plt.close()\n",
    "        \n",
    "        # save model to .h5 file in specified folder\n",
    "        self.generator.save(model_path + \"\\\\generator\" + str(epoch) + \".h5\")"
   ]
  },
  {
   "source": [
    "# Initialize Generator and Discriminator Models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_9 (Conv2D)            (None, 256, 256, 64)      4864      \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, 252, 252, 64)      102464    \n_________________________________________________________________\nleaky_re_lu_8 (LeakyReLU)    (None, 252, 252, 64)      0         \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 126, 126, 64)      0         \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, 61, 61, 64)        102464    \n_________________________________________________________________\nleaky_re_lu_9 (LeakyReLU)    (None, 61, 61, 64)        0         \n_________________________________________________________________\nconv2d_12 (Conv2D)           (None, 29, 29, 64)        102464    \n_________________________________________________________________\nleaky_re_lu_10 (LeakyReLU)   (None, 29, 29, 64)        0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 53824)             0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 53825     \n=================================================================\nTotal params: 366,081\nTrainable params: 366,081\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_13 (Conv2D)           (None, 128, 128, 64)      4864      \n_________________________________________________________________\nleaky_re_lu_11 (LeakyReLU)   (None, 128, 128, 64)      0         \n_________________________________________________________________\nconv2d_14 (Conv2D)           (None, 128, 128, 64)      102464    \n_________________________________________________________________\nleaky_re_lu_12 (LeakyReLU)   (None, 128, 128, 64)      0         \n_________________________________________________________________\nup_sampling2d_1 (UpSampling2 (None, 256, 256, 64)      0         \n_________________________________________________________________\nconv2d_15 (Conv2D)           (None, 256, 256, 64)      102464    \n_________________________________________________________________\nleaky_re_lu_13 (LeakyReLU)   (None, 256, 256, 64)      0         \n_________________________________________________________________\nconv2d_16 (Conv2D)           (None, 256, 256, 64)      102464    \n_________________________________________________________________\nleaky_re_lu_14 (LeakyReLU)   (None, 256, 256, 64)      0         \n_________________________________________________________________\nconv2d_17 (Conv2D)           (None, 256, 256, 3)       4803      \n_________________________________________________________________\nleaky_re_lu_15 (LeakyReLU)   (None, 256, 256, 3)       0         \n=================================================================\nTotal params: 317,059\nTrainable params: 317,059\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dcgan = DCGAN()"
   ]
  },
  {
   "source": [
    "# Train GAN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_loss, d_loss = dcgan.train(epochs=epoch, batch_size=batch, save_interval=interval)"
   ]
  },
  {
   "source": [
    "# Plot Loss"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(g_loss)\n",
    "plt.plot(d_loss)\n",
    "plt.title('GAN Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Generator', 'Discriminator'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}